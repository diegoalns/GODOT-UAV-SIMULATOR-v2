{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46853869",
   "metadata": {},
   "source": [
    "# 3D Lattice Graph Connectivity Analysis\n",
    "\n",
    "This notebook analyzes the connectivity properties of the 3D lattice graph for UAS (drone) path planning over Manhattan NYC. The graph represents a multi-layer airspace with nodes at different altitudes and horizontal connections forming a lattice structure.\n",
    "\n",
    "## Objectives:\n",
    "- Analyze graph connectivity patterns\n",
    "- Identify connected components\n",
    "- Evaluate path efficiency and reachability\n",
    "- Calculate network centrality measures\n",
    "- Visualize connectivity structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ab6eba",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for graph analysis and visualization\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting parameters\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"NetworkX version: {nx.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86897c8b",
   "metadata": {},
   "source": [
    "## 2. Load Graph from Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac174fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the graph from the pickle file\n",
    "pickle_filename = \"regular_lattice_graph.pkl\"\n",
    "\n",
    "try:\n",
    "    with open(pickle_filename, 'rb') as f:\n",
    "        graph_data = pickle.load(f)\n",
    "    \n",
    "    print(\"‚úÖ Pickle file loaded successfully!\")\n",
    "    print(f\"Data type: {type(graph_data)}\")\n",
    "    \n",
    "    # Extract the graph and metadata\n",
    "    if isinstance(graph_data, dict):\n",
    "        G = graph_data.get('graph')\n",
    "        metadata = graph_data.get('metadata', {})\n",
    "        print(f\"\\nüìä Metadata found:\")\n",
    "        for key, value in metadata.items():\n",
    "            print(f\"   {key}: {value}\")\n",
    "    else:\n",
    "        G = graph_data\n",
    "        metadata = {}\n",
    "        print(\"   No metadata found - using graph directly\")\n",
    "    \n",
    "    print(f\"\\nüéØ Graph loaded: {type(G)}\")\n",
    "    print(f\"   NetworkX Graph: {isinstance(G, nx.Graph)}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: {pickle_filename} not found in current directory\")\n",
    "    print(\"Please ensure the pickle file is in the same folder as this notebook\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a473cb",
   "metadata": {},
   "source": [
    "## 3. Basic Graph Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a5ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic graph information and structure analysis\n",
    "print(\"üîç BASIC GRAPH INFORMATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Graph type and basic stats\n",
    "print(f\"Graph Type: {type(G).__name__}\")\n",
    "print(f\"Is Directed: {G.is_directed()}\")\n",
    "print(f\"Is Multigraph: {G.is_multigraph()}\")\n",
    "print(f\"Number of Nodes: {G.number_of_nodes():,}\")\n",
    "print(f\"Number of Edges: {G.number_of_edges():,}\")\n",
    "\n",
    "if G.number_of_nodes() > 0:\n",
    "    print(f\"Average Degree: {sum(dict(G.degree()).values()) / G.number_of_nodes():.2f}\")\n",
    "\n",
    "# Node attributes analysis\n",
    "print(f\"\\nüìã NODE ATTRIBUTES:\")\n",
    "if G.nodes():\n",
    "    sample_node = list(G.nodes())[0]\n",
    "    node_attrs = G.nodes[sample_node]\n",
    "    print(f\"Sample node: {sample_node}\")\n",
    "    print(f\"Node attributes: {list(node_attrs.keys())}\")\n",
    "    \n",
    "    # Analyze node attributes\n",
    "    for attr in node_attrs.keys():\n",
    "        values = [G.nodes[n].get(attr) for n in G.nodes()]\n",
    "        unique_values = set([v for v in values if v is not None])\n",
    "        print(f\"  - {attr}: {len(unique_values)} unique values\")\n",
    "\n",
    "# Edge attributes analysis\n",
    "print(f\"\\nüîó EDGE ATTRIBUTES:\")\n",
    "if G.edges():\n",
    "    sample_edge = list(G.edges())[0]\n",
    "    edge_attrs = G.edges[sample_edge]\n",
    "    print(f\"Sample edge: {sample_edge}\")\n",
    "    print(f\"Edge attributes: {list(edge_attrs.keys())}\")\n",
    "    \n",
    "    # Analyze edge attributes\n",
    "    for attr in edge_attrs.keys():\n",
    "        values = [G.edges[e].get(attr) for e in G.edges()]\n",
    "        unique_values = set([v for v in values if v is not None])\n",
    "        print(f\"  - {attr}: {len(unique_values)} unique values\")\n",
    "\n",
    "# Degree distribution\n",
    "degrees = [d for n, d in G.degree()]\n",
    "print(f\"\\nüìä DEGREE DISTRIBUTION:\")\n",
    "print(f\"Min degree: {min(degrees)}\")\n",
    "print(f\"Max degree: {max(degrees)}\")\n",
    "print(f\"Mean degree: {np.mean(degrees):.2f}\")\n",
    "print(f\"Median degree: {np.median(degrees):.2f}\")\n",
    "print(f\"Standard deviation: {np.std(degrees):.2f}\")\n",
    "\n",
    "# Count nodes by degree\n",
    "degree_counts = Counter(degrees)\n",
    "print(f\"\\nDegree frequency:\")\n",
    "for degree in sorted(degree_counts.keys()):\n",
    "    count = degree_counts[degree]\n",
    "    percentage = (count / len(degrees)) * 100\n",
    "    print(f\"  Degree {degree}: {count} nodes ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a8026",
   "metadata": {},
   "source": [
    "### 3.1 Edge Direction Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5867b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed verification of directed vs undirected edges\n",
    "print(\"üîç DIRECTED vs UNDIRECTED EDGE VERIFICATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if the graph data contains both directed and undirected information\n",
    "total_edges = G.number_of_edges()\n",
    "directed_edges = 0\n",
    "undirected_edges = 0\n",
    "bidirectional_pairs = 0\n",
    "\n",
    "print(f\"Graph is classified as: {'Directed' if G.is_directed() else 'Undirected'}\")\n",
    "print(f\"Total edges in graph: {total_edges:,}\")\n",
    "\n",
    "if G.is_directed():\n",
    "    # For directed graphs, check for bidirectional connections\n",
    "    print(f\"\\nüîÑ ANALYZING DIRECTED GRAPH EDGE PATTERNS:\")\n",
    "    \n",
    "    edge_pairs = {}  # Track (u,v) and (v,u) pairs\n",
    "    \n",
    "    for u, v in G.edges():\n",
    "        # Create a canonical pair representation\n",
    "        pair = tuple(sorted([u, v]))\n",
    "        \n",
    "        if pair not in edge_pairs:\n",
    "            edge_pairs[pair] = []\n",
    "        edge_pairs[pair].append((u, v))\n",
    "    \n",
    "    # Analyze the patterns\n",
    "    unidirectional_pairs = 0\n",
    "    bidirectional_pairs = 0\n",
    "    \n",
    "    for pair, edges in edge_pairs.items():\n",
    "        if len(edges) == 1:\n",
    "            unidirectional_pairs += 1\n",
    "        elif len(edges) == 2:\n",
    "            bidirectional_pairs += 1\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Unusual: {len(edges)} edges for pair {pair}\")\n",
    "    \n",
    "    print(f\"  Unidirectional pairs: {unidirectional_pairs:,} (single direction)\")\n",
    "    print(f\"  Bidirectional pairs: {bidirectional_pairs:,} (both directions)\")\n",
    "    print(f\"  Total node pairs with edges: {len(edge_pairs):,}\")\n",
    "    \n",
    "    # Calculate edge counts\n",
    "    directed_edges = unidirectional_pairs + (bidirectional_pairs * 2)\n",
    "    \n",
    "    print(f\"\\nüìä EDGE COUNT BREAKDOWN:\")\n",
    "    print(f\"  Unidirectional edges: {unidirectional_pairs:,}\")\n",
    "    print(f\"  Bidirectional edges: {bidirectional_pairs * 2:,} (from {bidirectional_pairs:,} pairs)\")\n",
    "    print(f\"  Total directed edges: {directed_edges:,}\")\n",
    "    \n",
    "    # Verify totals\n",
    "    if directed_edges == total_edges:\n",
    "        print(f\"  ‚úÖ Edge count verification: PASSED\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå Edge count verification: FAILED (expected {total_edges}, calculated {directed_edges})\")\n",
    "    \n",
    "    # Calculate what this would look like as undirected\n",
    "    equivalent_undirected_edges = unidirectional_pairs + bidirectional_pairs\n",
    "    print(f\"\\nüîÑ IF CONVERTED TO UNDIRECTED:\")\n",
    "    print(f\"  Equivalent undirected edges: {equivalent_undirected_edges:,}\")\n",
    "    print(f\"  Reduction factor: {total_edges / equivalent_undirected_edges:.2f}x\")\n",
    "    \n",
    "    # Check for self-loops\n",
    "    self_loops = list(nx.selfloop_edges(G))\n",
    "    print(f\"\\nüîÑ SELF-LOOPS:\")\n",
    "    print(f\"  Number of self-loops: {len(self_loops)}\")\n",
    "    if len(self_loops) > 0 and len(self_loops) <= 10:\n",
    "        print(f\"  Self-loop nodes: {[edge[0] for edge in self_loops]}\")\n",
    "    elif len(self_loops) > 10:\n",
    "        print(f\"  First 10 self-loop nodes: {[edge[0] for edge in self_loops[:10]]}\")\n",
    "\n",
    "else:\n",
    "    # For undirected graphs, all edges are undirected\n",
    "    print(f\"\\n‚ÜîÔ∏è  ANALYZING UNDIRECTED GRAPH:\")\n",
    "    undirected_edges = total_edges\n",
    "    \n",
    "    print(f\"  All edges are undirected: {undirected_edges:,}\")\n",
    "    \n",
    "    # Check what this would look like as directed\n",
    "    print(f\"\\nüîÑ IF CONVERTED TO DIRECTED:\")\n",
    "    print(f\"  Would create: {undirected_edges * 2:,} directed edges\")\n",
    "    print(f\"  Expansion factor: 2.0x\")\n",
    "    \n",
    "    # Check for self-loops\n",
    "    self_loops = list(nx.selfloop_edges(G))\n",
    "    print(f\"\\nüîÑ SELF-LOOPS:\")\n",
    "    print(f\"  Number of self-loops: {len(self_loops)}\")\n",
    "    if len(self_loops) > 0 and len(self_loops) <= 10:\n",
    "        print(f\"  Self-loop nodes: {[edge[0] for edge in self_loops]}\")\n",
    "    elif len(self_loops) > 10:\n",
    "        print(f\"  First 10 self-loop nodes: {[edge[0] for edge in self_loops[:10]]}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nüìã SUMMARY:\")\n",
    "print(f\"  Graph type: {'Directed' if G.is_directed() else 'Undirected'}\")\n",
    "print(f\"  Total edges: {total_edges:,}\")\n",
    "\n",
    "if G.is_directed():\n",
    "    print(f\"  Bidirectional pairs: {bidirectional_pairs:,}\")\n",
    "    print(f\"  Unidirectional pairs: {unidirectional_pairs:,}\")\n",
    "    connectivity_ratio = bidirectional_pairs / (bidirectional_pairs + unidirectional_pairs) if (bidirectional_pairs + unidirectional_pairs) > 0 else 0\n",
    "    print(f\"  Bidirectionality ratio: {connectivity_ratio:.1%}\")\n",
    "else:\n",
    "    print(f\"  All edges are inherently bidirectional\")\n",
    "\n",
    "print(f\"\\n‚úÖ Edge direction verification completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f672530a",
   "metadata": {},
   "source": [
    "### 3.2 Vertical Layer Connectivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f49d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze vertical connections between altitude layers in the 3D lattice\n",
    "print(\"üèóÔ∏è VERTICAL LAYER CONNECTIVITY ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Extract layer information from node attributes\n",
    "layer_nodes = {}  # layer -> list of nodes\n",
    "node_layers = {}  # node -> layer\n",
    "layer_coordinates = {}  # layer -> set of (x,y) coordinates\n",
    "\n",
    "print(\"üìä ANALYZING NODE LAYER DISTRIBUTION:\")\n",
    "\n",
    "# Analyze node attributes to identify layers\n",
    "if G.nodes():\n",
    "    sample_node = list(G.nodes())[0]\n",
    "    node_attrs = G.nodes[sample_node]\n",
    "    \n",
    "    # Check for common layer attribute names\n",
    "    layer_attr = None\n",
    "    for attr in ['layer', 'altitude', 'z', 'level', 'floor']:\n",
    "        if attr in node_attrs:\n",
    "            layer_attr = attr\n",
    "            break\n",
    "    \n",
    "    if layer_attr:\n",
    "        print(f\"Found layer attribute: '{layer_attr}'\")\n",
    "        \n",
    "        # Group nodes by layer\n",
    "        for node in G.nodes():\n",
    "            layer = G.nodes[node].get(layer_attr, 'unknown')\n",
    "            \n",
    "            if layer not in layer_nodes:\n",
    "                layer_nodes[layer] = []\n",
    "            layer_nodes[layer].append(node)\n",
    "            node_layers[node] = layer\n",
    "            \n",
    "            # Also collect x,y coordinates if available\n",
    "            if layer not in layer_coordinates:\n",
    "                layer_coordinates[layer] = set()\n",
    "            \n",
    "            x_coord = G.nodes[node].get('x', G.nodes[node].get('lon', None))\n",
    "            y_coord = G.nodes[node].get('y', G.nodes[node].get('lat', None))\n",
    "            \n",
    "            if x_coord is not None and y_coord is not None:\n",
    "                layer_coordinates[layer].add((x_coord, y_coord))\n",
    "        \n",
    "        print(f\"Identified {len(layer_nodes)} distinct layers:\")\n",
    "        for layer in sorted(layer_nodes.keys()):\n",
    "            nodes_in_layer = len(layer_nodes[layer])\n",
    "            coords_in_layer = len(layer_coordinates.get(layer, set()))\n",
    "            print(f\"  Layer {layer}: {nodes_in_layer} nodes, {coords_in_layer} unique coordinates\")\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No standard layer attribute found. Attempting coordinate-based analysis...\")\n",
    "        \n",
    "        # Try to infer layers from z-coordinate or altitude\n",
    "        z_values = set()\n",
    "        for node in G.nodes():\n",
    "            z_val = None\n",
    "            for attr in ['z', 'altitude', 'alt', 'height', 'elevation']:\n",
    "                if attr in G.nodes[node]:\n",
    "                    z_val = G.nodes[node][attr]\n",
    "                    break\n",
    "            \n",
    "            if z_val is not None:\n",
    "                z_values.add(z_val)\n",
    "                node_layers[node] = z_val\n",
    "                \n",
    "                if z_val not in layer_nodes:\n",
    "                    layer_nodes[z_val] = []\n",
    "                layer_nodes[z_val].append(node)\n",
    "        \n",
    "        if z_values:\n",
    "            print(f\"Inferred {len(z_values)} layers from z-coordinates: {sorted(z_values)}\")\n",
    "        else:\n",
    "            print(\"‚ùå Could not identify layer structure from node attributes\")\n",
    "\n",
    "# Analyze vertical connections\n",
    "if len(layer_nodes) > 1:\n",
    "    print(f\"\\nüîó VERTICAL CONNECTION ANALYSIS:\")\n",
    "    \n",
    "    vertical_edges = []\n",
    "    horizontal_edges = []\n",
    "    same_layer_edges = []\n",
    "    \n",
    "    # Classify edges by their vertical nature\n",
    "    for u, v in G.edges():\n",
    "        u_layer = node_layers.get(u, 'unknown')\n",
    "        v_layer = node_layers.get(v, 'unknown')\n",
    "        \n",
    "        if u_layer != 'unknown' and v_layer != 'unknown':\n",
    "            if u_layer == v_layer:\n",
    "                same_layer_edges.append((u, v))\n",
    "            else:\n",
    "                vertical_edges.append((u, v, u_layer, v_layer))\n",
    "        else:\n",
    "            horizontal_edges.append((u, v))  # Unknown layer classification\n",
    "    \n",
    "    print(f\"Total edges analyzed: {len(list(G.edges()))}\")\n",
    "    print(f\"Same-layer (horizontal) edges: {len(same_layer_edges)}\")\n",
    "    print(f\"Vertical (inter-layer) edges: {len(vertical_edges)}\")\n",
    "    print(f\"Unclassified edges: {len(horizontal_edges)}\")\n",
    "    \n",
    "    # Analyze vertical edge patterns\n",
    "    if vertical_edges:\n",
    "        print(f\"\\nüìà VERTICAL EDGE PATTERNS:\")\n",
    "        \n",
    "        layer_transitions = {}  # (from_layer, to_layer) -> count\n",
    "        vertical_node_pairs = {}  # (node1, node2) -> edge_info\n",
    "        \n",
    "        for u, v, u_layer, v_layer in vertical_edges:\n",
    "            # Create canonical layer transition\n",
    "            transition = tuple(sorted([u_layer, v_layer]))\n",
    "            if transition not in layer_transitions:\n",
    "                layer_transitions[transition] = 0\n",
    "            layer_transitions[transition] += 1\n",
    "            \n",
    "            # Track node pairs for bidirectionality analysis\n",
    "            node_pair = tuple(sorted([u, v]))\n",
    "            if node_pair not in vertical_node_pairs:\n",
    "                vertical_node_pairs[node_pair] = []\n",
    "            vertical_node_pairs[node_pair].append((u, v, u_layer, v_layer))\n",
    "        \n",
    "        # Display transition patterns\n",
    "        print(f\"Layer transition patterns:\")\n",
    "        for transition, count in sorted(layer_transitions.items()):\n",
    "            layer1, layer2 = transition\n",
    "            print(f\"  Layers {layer1} ‚Üî {layer2}: {count} edges\")\n",
    "        \n",
    "        # Check bidirectionality of vertical connections\n",
    "        bidirectional_vertical = 0\n",
    "        unidirectional_vertical = 0\n",
    "        \n",
    "        for node_pair, edges in vertical_node_pairs.items():\n",
    "            if len(edges) == 1:\n",
    "                unidirectional_vertical += 1\n",
    "            elif len(edges) == 2:\n",
    "                bidirectional_vertical += 1\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Unusual vertical connection: {len(edges)} edges for {node_pair}\")\n",
    "        \n",
    "        print(f\"\\nüîÑ VERTICAL BIDIRECTIONALITY:\")\n",
    "        print(f\"  Bidirectional vertical pairs: {bidirectional_vertical}\")\n",
    "        print(f\"  Unidirectional vertical pairs: {unidirectional_vertical}\")\n",
    "        \n",
    "        total_vertical_pairs = bidirectional_vertical + unidirectional_vertical\n",
    "        if total_vertical_pairs > 0:\n",
    "            vertical_bidir_ratio = bidirectional_vertical / total_vertical_pairs\n",
    "            print(f\"  Vertical bidirectionality ratio: {vertical_bidir_ratio:.1%}\")\n",
    "        \n",
    "        # Check if vertical edges are undirected (bidirectional)\n",
    "        if G.is_directed():\n",
    "            undirected_vertical_connections = bidirectional_vertical\n",
    "            directed_vertical_connections = unidirectional_vertical\n",
    "            \n",
    "            print(f\"\\nüéØ VERTICAL EDGE NATURE:\")\n",
    "            print(f\"  Effectively undirected vertical connections: {undirected_vertical_connections}\")\n",
    "            print(f\"  Truly directed vertical connections: {directed_vertical_connections}\")\n",
    "            \n",
    "            if undirected_vertical_connections > 0:\n",
    "                print(f\"  ‚úÖ Found {undirected_vertical_connections} undirected vertical connections!\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå No undirected vertical connections found\")\n",
    "        else:\n",
    "            print(f\"\\nüéØ VERTICAL EDGE NATURE:\")\n",
    "            print(f\"  All vertical edges are inherently undirected: {len(vertical_edges)}\")\n",
    "            print(f\"  ‚úÖ All vertical connections are undirected by graph nature!\")\n",
    "        \n",
    "        # Analyze vertical connectivity by coordinate\n",
    "        if layer_coordinates and len(layer_coordinates) > 1:\n",
    "            print(f\"\\nüìç COORDINATE-BASED VERTICAL ANALYSIS:\")\n",
    "            \n",
    "            # Check if same (x,y) coordinates exist across layers\n",
    "            common_coordinates = None\n",
    "            for layer in layer_coordinates:\n",
    "                if common_coordinates is None:\n",
    "                    common_coordinates = layer_coordinates[layer].copy()\n",
    "                else:\n",
    "                    common_coordinates &= layer_coordinates[layer]\n",
    "            \n",
    "            if common_coordinates:\n",
    "                print(f\"  Common (x,y) coordinates across layers: {len(common_coordinates)}\")\n",
    "                print(f\"  This suggests a regular 3D lattice structure\")\n",
    "                \n",
    "                # Sample a few vertical stacks\n",
    "                sample_coords = list(common_coordinates)[:5]\n",
    "                for coord in sample_coords:\n",
    "                    vertical_stack = []\n",
    "                    for layer in sorted(layer_nodes.keys()):\n",
    "                        for node in layer_nodes[layer]:\n",
    "                            x_coord = G.nodes[node].get('x', G.nodes[node].get('lon', None))\n",
    "                            y_coord = G.nodes[node].get('y', G.nodes[node].get('lat', None))\n",
    "                            if x_coord is not None and y_coord is not None:\n",
    "                                if (x_coord, y_coord) == coord:\n",
    "                                    vertical_stack.append((node, layer))\n",
    "                    \n",
    "                    if len(vertical_stack) > 1:\n",
    "                        print(f\"    Vertical stack at {coord}: {len(vertical_stack)} nodes\")\n",
    "                        \n",
    "                        # Check connections within this stack\n",
    "                        stack_connections = 0\n",
    "                        for i in range(len(vertical_stack) - 1):\n",
    "                            node1, layer1 = vertical_stack[i]\n",
    "                            for j in range(i + 1, len(vertical_stack)):\n",
    "                                node2, layer2 = vertical_stack[j]\n",
    "                                if G.has_edge(node1, node2) or G.has_edge(node2, node1):\n",
    "                                    stack_connections += 1\n",
    "                        \n",
    "                        max_possible = len(vertical_stack) * (len(vertical_stack) - 1) // 2\n",
    "                        if not G.is_directed():\n",
    "                            max_possible = len(vertical_stack) - 1  # Adjacent layers only typically\n",
    "                        \n",
    "                        print(f\"      Connections in stack: {stack_connections}\")\n",
    "            else:\n",
    "                print(f\"  No common coordinates across layers - irregular structure\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"\\n‚ùå No vertical edges found between layers\")\n",
    "        print(f\"   All {len(same_layer_edges)} edges are within the same layer\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Cannot analyze vertical connections:\")\n",
    "    if len(layer_nodes) <= 1:\n",
    "        print(f\"   Only {len(layer_nodes)} layer(s) identified\")\n",
    "    else:\n",
    "        print(f\"   Layer structure could not be determined\")\n",
    "\n",
    "print(f\"\\n‚úÖ Vertical layer connectivity analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7125af48",
   "metadata": {},
   "source": [
    "## 4. Connectivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891da883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive connectivity analysis\n",
    "print(\"üåê GRAPH CONNECTIVITY ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Basic connectivity checks\n",
    "if G.is_directed():\n",
    "    print(\"üîÑ DIRECTED GRAPH CONNECTIVITY:\")\n",
    "    is_strongly_connected = nx.is_strongly_connected(G)\n",
    "    is_weakly_connected = nx.is_weakly_connected(G)\n",
    "    print(f\"Strongly Connected: {is_strongly_connected}\")\n",
    "    print(f\"Weakly Connected: {is_weakly_connected}\")\n",
    "    \n",
    "    if not is_strongly_connected:\n",
    "        num_strongly_connected = nx.number_strongly_connected_components(G)\n",
    "        print(f\"Number of Strongly Connected Components: {num_strongly_connected}\")\n",
    "    \n",
    "    if not is_weakly_connected:\n",
    "        num_weakly_connected = nx.number_weakly_connected_components(G)\n",
    "        print(f\"Number of Weakly Connected Components: {num_weakly_connected}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ÜîÔ∏è UNDIRECTED GRAPH CONNECTIVITY:\")\n",
    "    is_connected = nx.is_connected(G)\n",
    "    print(f\"Connected: {is_connected}\")\n",
    "    \n",
    "    if not is_connected:\n",
    "        num_components = nx.number_connected_components(G)\n",
    "        print(f\"Number of Connected Components: {num_components}\")\n",
    "\n",
    "# Node and Edge connectivity (for smaller graphs)\n",
    "if G.number_of_nodes() < 1000:\n",
    "    try:\n",
    "        if G.is_directed():\n",
    "            node_connectivity = nx.node_connectivity(G)\n",
    "            edge_connectivity = nx.edge_connectivity(G)\n",
    "        else:\n",
    "            node_connectivity = nx.node_connectivity(G)\n",
    "            edge_connectivity = nx.edge_connectivity(G)\n",
    "        \n",
    "        print(f\"\\nüîó CONNECTIVITY MEASURES:\")\n",
    "        print(f\"Node Connectivity: {node_connectivity}\")\n",
    "        print(f\"Edge Connectivity: {edge_connectivity}\")\n",
    "        \n",
    "    except nx.NetworkXError as e:\n",
    "        print(f\"\\n‚ö†Ô∏è Connectivity measures not available: {e}\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Graph too large ({G.number_of_nodes()} nodes) for detailed connectivity measures\")\n",
    "\n",
    "# Density analysis\n",
    "if G.is_directed():\n",
    "    density = nx.density(G)\n",
    "    max_edges = G.number_of_nodes() * (G.number_of_nodes() - 1)\n",
    "else:\n",
    "    density = nx.density(G)\n",
    "    max_edges = G.number_of_nodes() * (G.number_of_nodes() - 1) // 2\n",
    "\n",
    "print(f\"\\nüìä DENSITY ANALYSIS:\")\n",
    "print(f\"Graph Density: {density:.6f}\")\n",
    "print(f\"Current Edges: {G.number_of_edges():,}\")\n",
    "print(f\"Maximum Possible Edges: {max_edges:,}\")\n",
    "print(f\"Edge Utilization: {(G.number_of_edges() / max_edges * 100):.2f}%\")\n",
    "\n",
    "# Isolated nodes\n",
    "isolated_nodes = list(nx.isolates(G))\n",
    "print(f\"\\nüèùÔ∏è ISOLATED NODES:\")\n",
    "print(f\"Number of Isolated Nodes: {len(isolated_nodes)}\")\n",
    "if len(isolated_nodes) > 0 and len(isolated_nodes) <= 10:\n",
    "    print(f\"Isolated Nodes: {isolated_nodes}\")\n",
    "elif len(isolated_nodes) > 10:\n",
    "    print(f\"First 10 Isolated Nodes: {isolated_nodes[:10]}\")\n",
    "\n",
    "# Self-loops and multiple edges\n",
    "if hasattr(G, 'number_of_selfloops'):\n",
    "    self_loops = nx.number_of_selfloops(G)\n",
    "    print(f\"\\nüîÑ SELF-LOOPS:\")\n",
    "    print(f\"Number of Self-loops: {self_loops}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Connectivity analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcaa038",
   "metadata": {},
   "source": [
    "## 5. Connected Components Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5921b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of connected components\n",
    "print(\"üß© CONNECTED COMPONENTS ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if G.is_directed():\n",
    "    # Strongly connected components\n",
    "    print(\"üí™ STRONGLY CONNECTED COMPONENTS:\")\n",
    "    scc = list(nx.strongly_connected_components(G))\n",
    "    scc_sizes = [len(component) for component in scc]\n",
    "    \n",
    "    print(f\"Number of Strongly Connected Components: {len(scc)}\")\n",
    "    print(f\"Largest SCC size: {max(scc_sizes) if scc_sizes else 0}\")\n",
    "    print(f\"Smallest SCC size: {min(scc_sizes) if scc_sizes else 0}\")\n",
    "    print(f\"Average SCC size: {np.mean(scc_sizes):.2f}\" if scc_sizes else \"N/A\")\n",
    "    \n",
    "    # Size distribution\n",
    "    scc_size_counts = Counter(scc_sizes)\n",
    "    print(f\"\\nSCC Size Distribution:\")\n",
    "    for size in sorted(scc_size_counts.keys(), reverse=True)[:10]:\n",
    "        count = scc_size_counts[size]\n",
    "        percentage = (count / len(scc)) * 100\n",
    "        print(f\"  Size {size}: {count} components ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Weakly connected components\n",
    "    print(f\"\\nü§ù WEAKLY CONNECTED COMPONENTS:\")\n",
    "    wcc = list(nx.weakly_connected_components(G))\n",
    "    wcc_sizes = [len(component) for component in wcc]\n",
    "    \n",
    "    print(f\"Number of Weakly Connected Components: {len(wcc)}\")\n",
    "    print(f\"Largest WCC size: {max(wcc_sizes) if wcc_sizes else 0}\")\n",
    "    print(f\"Smallest WCC size: {min(wcc_sizes) if wcc_sizes else 0}\")\n",
    "    print(f\"Average WCC size: {np.mean(wcc_sizes):.2f}\" if wcc_sizes else \"N/A\")\n",
    "\n",
    "else:\n",
    "    # Connected components for undirected graph\n",
    "    print(\"üîó CONNECTED COMPONENTS:\")\n",
    "    cc = list(nx.connected_components(G))\n",
    "    cc_sizes = [len(component) for component in cc]\n",
    "    \n",
    "    print(f\"Number of Connected Components: {len(cc)}\")\n",
    "    if cc_sizes:\n",
    "        print(f\"Largest Component size: {max(cc_sizes)} nodes ({max(cc_sizes)/G.number_of_nodes()*100:.1f}% of total)\")\n",
    "        print(f\"Smallest Component size: {min(cc_sizes)} nodes\")\n",
    "        print(f\"Average Component size: {np.mean(cc_sizes):.2f}\")\n",
    "        \n",
    "        # Size distribution\n",
    "        cc_size_counts = Counter(cc_sizes)\n",
    "        print(f\"\\nComponent Size Distribution:\")\n",
    "        for size in sorted(cc_size_counts.keys(), reverse=True)[:10]:\n",
    "            count = cc_size_counts[size]\n",
    "            percentage = (count / len(cc)) * 100\n",
    "            nodes_in_size = size * count\n",
    "            nodes_percentage = (nodes_in_size / G.number_of_nodes()) * 100\n",
    "            print(f\"  Size {size}: {count} components ({percentage:.1f}% of components, {nodes_percentage:.1f}% of nodes)\")\n",
    "\n",
    "# Analyze largest component in detail\n",
    "if G.is_directed():\n",
    "    largest_wcc = max(wcc, key=len) if wcc else set()\n",
    "    largest_component_size = len(largest_wcc)\n",
    "    component_type = \"Weakly Connected Component\"\n",
    "else:\n",
    "    largest_cc = max(cc, key=len) if cc else set()\n",
    "    largest_component_size = len(largest_cc)\n",
    "    component_type = \"Connected Component\"\n",
    "\n",
    "print(f\"\\nüéØ LARGEST {component_type.upper()} ANALYSIS:\")\n",
    "print(f\"Size: {largest_component_size} nodes ({largest_component_size/G.number_of_nodes()*100:.1f}% of total)\")\n",
    "\n",
    "if largest_component_size > 0:\n",
    "    if G.is_directed():\n",
    "        largest_subgraph = G.subgraph(largest_wcc)\n",
    "    else:\n",
    "        largest_subgraph = G.subgraph(largest_cc)\n",
    "    \n",
    "    print(f\"Edges in largest component: {largest_subgraph.number_of_edges()}\")\n",
    "    print(f\"Density of largest component: {nx.density(largest_subgraph):.6f}\")\n",
    "    \n",
    "    # Degree statistics for largest component\n",
    "    largest_degrees = [d for n, d in largest_subgraph.degree()]\n",
    "    if largest_degrees:\n",
    "        print(f\"Average degree in largest component: {np.mean(largest_degrees):.2f}\")\n",
    "        print(f\"Degree range in largest component: {min(largest_degrees)} - {max(largest_degrees)}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Connected components analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5757b7",
   "metadata": {},
   "source": [
    "## 6. Path Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortest path and reachability analysis\n",
    "print(\"üõ§Ô∏è PATH ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# For large graphs, we'll sample nodes for path analysis\n",
    "max_nodes_for_path_analysis = 500\n",
    "nodes_list = list(G.nodes())\n",
    "\n",
    "if len(nodes_list) <= max_nodes_for_path_analysis:\n",
    "    sample_nodes = nodes_list\n",
    "    print(f\"Analyzing paths for all {len(sample_nodes)} nodes\")\n",
    "else:\n",
    "    # Sample nodes for analysis\n",
    "    np.random.seed(42)  # For reproducible results\n",
    "    sample_size = min(max_nodes_for_path_analysis, len(nodes_list))\n",
    "    sample_nodes = np.random.choice(nodes_list, size=sample_size, replace=False)\n",
    "    print(f\"Analyzing paths for sample of {len(sample_nodes)} nodes (out of {len(nodes_list)} total)\")\n",
    "\n",
    "# Get the largest connected component for path analysis\n",
    "if G.is_directed():\n",
    "    if nx.is_strongly_connected(G):\n",
    "        largest_component = G\n",
    "        print(\"Using full graph (strongly connected)\")\n",
    "    else:\n",
    "        wcc = max(nx.weakly_connected_components(G), key=len)\n",
    "        largest_component = G.subgraph(wcc)\n",
    "        print(f\"Using largest weakly connected component ({len(wcc)} nodes)\")\n",
    "else:\n",
    "    if nx.is_connected(G):\n",
    "        largest_component = G\n",
    "        print(\"Using full graph (connected)\")\n",
    "    else:\n",
    "        cc = max(nx.connected_components(G), key=len)\n",
    "        largest_component = G.subgraph(cc)\n",
    "        print(f\"Using largest connected component ({len(cc)} nodes)\")\n",
    "\n",
    "# Calculate shortest path lengths within the largest component\n",
    "component_nodes = list(largest_component.nodes())\n",
    "sample_component_nodes = [n for n in sample_nodes if n in component_nodes]\n",
    "\n",
    "if len(sample_component_nodes) > 1:\n",
    "    print(f\"\\nüìè SHORTEST PATH ANALYSIS:\")\n",
    "    print(f\"Analyzing {len(sample_component_nodes)} nodes in largest component\")\n",
    "    \n",
    "    # Calculate shortest path lengths\n",
    "    path_lengths = []\n",
    "    reachable_pairs = 0\n",
    "    total_pairs = 0\n",
    "    \n",
    "    # Sample pairs to avoid excessive computation\n",
    "    max_pairs = 1000\n",
    "    pairs_to_check = min(max_pairs, len(sample_component_nodes) * (len(sample_component_nodes) - 1))\n",
    "    \n",
    "    print(f\"Checking {pairs_to_check} node pairs for shortest paths...\")\n",
    "    \n",
    "    for i, source in enumerate(sample_component_nodes[:int(np.sqrt(pairs_to_check))]):\n",
    "        for target in sample_component_nodes[i+1:int(np.sqrt(pairs_to_check))]:\n",
    "            total_pairs += 1\n",
    "            try:\n",
    "                if G.is_directed():\n",
    "                    length = nx.shortest_path_length(largest_component, source, target)\n",
    "                else:\n",
    "                    length = nx.shortest_path_length(largest_component, source, target)\n",
    "                path_lengths.append(length)\n",
    "                reachable_pairs += 1\n",
    "            except nx.NetworkXNoPath:\n",
    "                pass  # Nodes not connected\n",
    "    \n",
    "    if path_lengths:\n",
    "        print(f\"\\nüìä PATH LENGTH STATISTICS:\")\n",
    "        print(f\"Total pairs checked: {total_pairs}\")\n",
    "        print(f\"Reachable pairs: {reachable_pairs} ({reachable_pairs/total_pairs*100:.1f}%)\")\n",
    "        print(f\"Average shortest path length: {np.mean(path_lengths):.2f}\")\n",
    "        print(f\"Median shortest path length: {np.median(path_lengths):.2f}\")\n",
    "        print(f\"Min path length: {min(path_lengths)}\")\n",
    "        print(f\"Max path length: {max(path_lengths)}\")\n",
    "        print(f\"Standard deviation: {np.std(path_lengths):.2f}\")\n",
    "        \n",
    "        # Path length distribution\n",
    "        path_length_counts = Counter(path_lengths)\n",
    "        print(f\"\\nPath Length Distribution:\")\n",
    "        for length in sorted(path_length_counts.keys()):\n",
    "            count = path_length_counts[length]\n",
    "            percentage = (count / len(path_lengths)) * 100\n",
    "            print(f\"  Length {length}: {count} paths ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Diameter and radius (for smaller components)\n",
    "    if len(component_nodes) <= 100:\n",
    "        try:\n",
    "            if G.is_directed():\n",
    "                if nx.is_strongly_connected(largest_component):\n",
    "                    diameter = nx.diameter(largest_component)\n",
    "                    radius = nx.radius(largest_component)\n",
    "                    print(f\"\\nüéØ GRAPH DIAMETER & RADIUS:\")\n",
    "                    print(f\"Diameter: {diameter}\")\n",
    "                    print(f\"Radius: {radius}\")\n",
    "                else:\n",
    "                    print(f\"\\n‚ö†Ô∏è Cannot calculate diameter/radius: not strongly connected\")\n",
    "            else:\n",
    "                diameter = nx.diameter(largest_component)\n",
    "                radius = nx.radius(largest_component)\n",
    "                print(f\"\\nüéØ GRAPH DIAMETER & RADIUS:\")\n",
    "                print(f\"Diameter: {diameter}\")\n",
    "                print(f\"Radius: {radius}\")\n",
    "        except nx.NetworkXError as e:\n",
    "            print(f\"\\n‚ö†Ô∏è Cannot calculate diameter/radius: {e}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Component too large ({len(component_nodes)} nodes) for diameter calculation\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Insufficient nodes in largest component for path analysis\")\n",
    "\n",
    "# Average clustering coefficient\n",
    "print(f\"\\nüï∏Ô∏è CLUSTERING ANALYSIS:\")\n",
    "try:\n",
    "    if G.is_directed():\n",
    "        clustering = nx.average_clustering(G)\n",
    "        print(f\"Average Clustering Coefficient: {clustering:.4f}\")\n",
    "    else:\n",
    "        clustering = nx.average_clustering(G)\n",
    "        print(f\"Average Clustering Coefficient: {clustering:.4f}\")\n",
    "        \n",
    "    # Transitivity\n",
    "    transitivity = nx.transitivity(G)\n",
    "    print(f\"Transitivity: {transitivity:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not calculate clustering: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Path analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6934269",
   "metadata": {},
   "source": [
    "## 7. Centrality Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bbed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate centrality measures to identify important nodes for connectivity\n",
    "print(\"üéØ CENTRALITY MEASURES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# For large graphs, we'll work with a subset or the largest component\n",
    "max_nodes_for_centrality = 1000\n",
    "\n",
    "if G.number_of_nodes() <= max_nodes_for_centrality:\n",
    "    analysis_graph = G\n",
    "    print(f\"Calculating centrality for full graph ({G.number_of_nodes()} nodes)\")\n",
    "else:\n",
    "    # Use largest connected component\n",
    "    if G.is_directed():\n",
    "        largest_cc = max(nx.weakly_connected_components(G), key=len)\n",
    "    else:\n",
    "        largest_cc = max(nx.connected_components(G), key=len)\n",
    "    \n",
    "    if len(largest_cc) <= max_nodes_for_centrality:\n",
    "        analysis_graph = G.subgraph(largest_cc)\n",
    "        print(f\"Calculating centrality for largest component ({len(largest_cc)} nodes)\")\n",
    "    else:\n",
    "        # Sample from largest component\n",
    "        np.random.seed(42)\n",
    "        sample_nodes = np.random.choice(list(largest_cc), size=max_nodes_for_centrality, replace=False)\n",
    "        analysis_graph = G.subgraph(sample_nodes)\n",
    "        print(f\"Calculating centrality for sample of largest component ({max_nodes_for_centrality} nodes)\")\n",
    "\n",
    "print(f\"Analysis graph: {analysis_graph.number_of_nodes()} nodes, {analysis_graph.number_of_edges()} edges\")\n",
    "\n",
    "# 1. Degree Centrality\n",
    "print(f\"\\nüìä DEGREE CENTRALITY:\")\n",
    "degree_centrality = nx.degree_centrality(analysis_graph)\n",
    "deg_cent_values = list(degree_centrality.values())\n",
    "\n",
    "print(f\"Average Degree Centrality: {np.mean(deg_cent_values):.4f}\")\n",
    "print(f\"Max Degree Centrality: {max(deg_cent_values):.4f}\")\n",
    "print(f\"Min Degree Centrality: {min(deg_cent_values):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(deg_cent_values):.4f}\")\n",
    "\n",
    "# Top nodes by degree centrality\n",
    "top_degree_nodes = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(f\"\\nTop 5 nodes by Degree Centrality:\")\n",
    "for i, (node, centrality) in enumerate(top_degree_nodes, 1):\n",
    "    print(f\"  {i}. Node {node}: {centrality:.4f}\")\n",
    "\n",
    "# 2. Betweenness Centrality (for smaller graphs)\n",
    "if analysis_graph.number_of_nodes() <= 500:\n",
    "    print(f\"\\nüåâ BETWEENNESS CENTRALITY:\")\n",
    "    try:\n",
    "        betweenness_centrality = nx.betweenness_centrality(analysis_graph, k=min(100, analysis_graph.number_of_nodes()))\n",
    "        bet_cent_values = list(betweenness_centrality.values())\n",
    "        \n",
    "        print(f\"Average Betweenness Centrality: {np.mean(bet_cent_values):.4f}\")\n",
    "        print(f\"Max Betweenness Centrality: {max(bet_cent_values):.4f}\")\n",
    "        print(f\"Min Betweenness Centrality: {min(bet_cent_values):.4f}\")\n",
    "        print(f\"Standard Deviation: {np.std(bet_cent_values):.4f}\")\n",
    "        \n",
    "        # Top nodes by betweenness centrality\n",
    "        top_betweenness_nodes = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        print(f\"\\nTop 5 nodes by Betweenness Centrality:\")\n",
    "        for i, (node, centrality) in enumerate(top_betweenness_nodes, 1):\n",
    "            print(f\"  {i}. Node {node}: {centrality:.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Could not calculate betweenness centrality: {e}\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Graph too large for betweenness centrality calculation\")\n",
    "\n",
    "# 3. Closeness Centrality (for smaller connected components)\n",
    "if analysis_graph.number_of_nodes() <= 500:\n",
    "    print(f\"\\nüéØ CLOSENESS CENTRALITY:\")\n",
    "    try:\n",
    "        # Check if graph is connected enough for closeness centrality\n",
    "        if G.is_directed():\n",
    "            if nx.is_strongly_connected(analysis_graph):\n",
    "                closeness_centrality = nx.closeness_centrality(analysis_graph)\n",
    "                calc_closeness = True\n",
    "            else:\n",
    "                print(\"Graph not strongly connected - calculating for largest SCC\")\n",
    "                scc = max(nx.strongly_connected_components(analysis_graph), key=len)\n",
    "                if len(scc) >= 10:  # Only if component is reasonably large\n",
    "                    closeness_centrality = nx.closeness_centrality(analysis_graph.subgraph(scc))\n",
    "                    calc_closeness = True\n",
    "                else:\n",
    "                    calc_closeness = False\n",
    "        else:\n",
    "            if nx.is_connected(analysis_graph):\n",
    "                closeness_centrality = nx.closeness_centrality(analysis_graph)\n",
    "                calc_closeness = True\n",
    "            else:\n",
    "                print(\"Graph not connected - calculating for largest CC\")\n",
    "                cc = max(nx.connected_components(analysis_graph), key=len)\n",
    "                if len(cc) >= 10:  # Only if component is reasonably large\n",
    "                    closeness_centrality = nx.closeness_centrality(analysis_graph.subgraph(cc))\n",
    "                    calc_closeness = True\n",
    "                else:\n",
    "                    calc_closeness = False\n",
    "        \n",
    "        if calc_closeness:\n",
    "            close_cent_values = list(closeness_centrality.values())\n",
    "            \n",
    "            print(f\"Average Closeness Centrality: {np.mean(close_cent_values):.4f}\")\n",
    "            print(f\"Max Closeness Centrality: {max(close_cent_values):.4f}\")\n",
    "            print(f\"Min Closeness Centrality: {min(close_cent_values):.4f}\")\n",
    "            print(f\"Standard Deviation: {np.std(close_cent_values):.4f}\")\n",
    "            \n",
    "            # Top nodes by closeness centrality\n",
    "            top_closeness_nodes = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "            print(f\"\\nTop 5 nodes by Closeness Centrality:\")\n",
    "            for i, (node, centrality) in enumerate(top_closeness_nodes, 1):\n",
    "                print(f\"  {i}. Node {node}: {centrality:.4f}\")\n",
    "        else:\n",
    "            print(\"Cannot calculate closeness centrality - no suitable connected component\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Could not calculate closeness centrality: {e}\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Graph too large for closeness centrality calculation\")\n",
    "\n",
    "# 4. Eigenvector Centrality (if possible)\n",
    "print(f\"\\nüî¢ EIGENVECTOR CENTRALITY:\")\n",
    "try:\n",
    "    # Eigenvector centrality works best on undirected graphs or strongly connected directed graphs\n",
    "    if G.is_directed():\n",
    "        # Convert to undirected for eigenvector centrality\n",
    "        undirected_graph = analysis_graph.to_undirected()\n",
    "        eigenvector_centrality = nx.eigenvector_centrality(undirected_graph, max_iter=1000)\n",
    "        print(\"(Calculated on undirected version of graph)\")\n",
    "    else:\n",
    "        eigenvector_centrality = nx.eigenvector_centrality(analysis_graph, max_iter=1000)\n",
    "    \n",
    "    eig_cent_values = list(eigenvector_centrality.values())\n",
    "    \n",
    "    print(f\"Average Eigenvector Centrality: {np.mean(eig_cent_values):.4f}\")\n",
    "    print(f\"Max Eigenvector Centrality: {max(eig_cent_values):.4f}\")\n",
    "    print(f\"Min Eigenvector Centrality: {min(eig_cent_values):.4f}\")\n",
    "    print(f\"Standard Deviation: {np.std(eig_cent_values):.4f}\")\n",
    "    \n",
    "    # Top nodes by eigenvector centrality\n",
    "    top_eigenvector_nodes = sorted(eigenvector_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(f\"\\nTop 5 nodes by Eigenvector Centrality:\")\n",
    "    for i, (node, centrality) in enumerate(top_eigenvector_nodes, 1):\n",
    "        print(f\"  {i}. Node {node}: {centrality:.4f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not calculate eigenvector centrality: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Centrality analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb275232",
   "metadata": {},
   "source": [
    "## 8. Visualization of Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e7864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations to show connectivity patterns\n",
    "print(\"üìä CREATING CONNECTIVITY VISUALIZATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Set up the plotting\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "fig.suptitle('Graph Connectivity Analysis Visualizations', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Degree Distribution\n",
    "ax1 = axes[0, 0]\n",
    "degrees = [d for n, d in G.degree()]\n",
    "degree_counts = Counter(degrees)\n",
    "\n",
    "x_vals = list(degree_counts.keys())\n",
    "y_vals = list(degree_counts.values())\n",
    "\n",
    "ax1.bar(x_vals, y_vals, alpha=0.7, color='skyblue', edgecolor='navy')\n",
    "ax1.set_xlabel('Degree')\n",
    "ax1.set_ylabel('Number of Nodes')\n",
    "ax1.set_title('Degree Distribution')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistics text\n",
    "mean_degree = np.mean(degrees)\n",
    "median_degree = np.median(degrees)\n",
    "ax1.axvline(mean_degree, color='red', linestyle='--', alpha=0.7, label=f'Mean: {mean_degree:.1f}')\n",
    "ax1.axvline(median_degree, color='orange', linestyle='--', alpha=0.7, label=f'Median: {median_degree:.1f}')\n",
    "ax1.legend()\n",
    "\n",
    "# 2. Connected Components Size Distribution\n",
    "ax2 = axes[0, 1]\n",
    "if G.is_directed():\n",
    "    components = list(nx.weakly_connected_components(G))\n",
    "    title = 'Weakly Connected Components Size Distribution'\n",
    "else:\n",
    "    components = list(nx.connected_components(G))\n",
    "    title = 'Connected Components Size Distribution'\n",
    "\n",
    "component_sizes = [len(comp) for comp in components]\n",
    "size_counts = Counter(component_sizes)\n",
    "\n",
    "if len(size_counts) > 0:\n",
    "    x_vals = list(size_counts.keys())\n",
    "    y_vals = list(size_counts.values())\n",
    "    \n",
    "    if len(x_vals) <= 20:  # Bar plot for few components\n",
    "        ax2.bar(x_vals, y_vals, alpha=0.7, color='lightcoral', edgecolor='darkred')\n",
    "        ax2.set_xlabel('Component Size')\n",
    "        ax2.set_xticks(x_vals)\n",
    "    else:  # Histogram for many components\n",
    "        ax2.hist(component_sizes, bins=min(20, len(set(component_sizes))), alpha=0.7, color='lightcoral', edgecolor='darkred')\n",
    "        ax2.set_xlabel('Component Size')\n",
    "    \n",
    "    ax2.set_ylabel('Number of Components')\n",
    "    ax2.set_title(title)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add largest component info\n",
    "    largest_size = max(component_sizes)\n",
    "    ax2.axvline(largest_size, color='red', linestyle='--', alpha=0.7, \n",
    "                label=f'Largest: {largest_size} nodes')\n",
    "    ax2.legend()\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, 'No connected components\\nto display', \n",
    "             horizontalalignment='center', verticalalignment='center', \n",
    "             transform=ax2.transAxes, fontsize=12)\n",
    "    ax2.set_title(title)\n",
    "\n",
    "# 3. Path Length Distribution (if calculated)\n",
    "ax3 = axes[1, 0]\n",
    "try:\n",
    "    # Sample paths for visualization\n",
    "    sample_size = min(200, G.number_of_nodes())\n",
    "    sample_nodes = np.random.choice(list(G.nodes()), size=sample_size, replace=False)\n",
    "    \n",
    "    # Get largest component nodes for path calculation\n",
    "    if G.is_directed():\n",
    "        largest_comp = max(nx.weakly_connected_components(G), key=len)\n",
    "    else:\n",
    "        largest_comp = max(nx.connected_components(G), key=len)\n",
    "    \n",
    "    sample_comp_nodes = [n for n in sample_nodes if n in largest_comp]\n",
    "    \n",
    "    if len(sample_comp_nodes) > 10:\n",
    "        subgraph = G.subgraph(largest_comp)\n",
    "        path_lengths = []\n",
    "        \n",
    "        # Calculate sample of path lengths\n",
    "        for i in range(min(100, len(sample_comp_nodes))):\n",
    "            for j in range(i+1, min(i+10, len(sample_comp_nodes))):\n",
    "                try:\n",
    "                    length = nx.shortest_path_length(subgraph, sample_comp_nodes[i], sample_comp_nodes[j])\n",
    "                    path_lengths.append(length)\n",
    "                except nx.NetworkXNoPath:\n",
    "                    pass\n",
    "        \n",
    "        if path_lengths:\n",
    "            ax3.hist(path_lengths, bins=range(1, max(path_lengths)+2), alpha=0.7, \n",
    "                    color='lightgreen', edgecolor='darkgreen')\n",
    "            ax3.set_xlabel('Path Length')\n",
    "            ax3.set_ylabel('Frequency')\n",
    "            ax3.set_title('Shortest Path Length Distribution\\n(Sample)')\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add mean\n",
    "            mean_path = np.mean(path_lengths)\n",
    "            ax3.axvline(mean_path, color='red', linestyle='--', alpha=0.7, \n",
    "                       label=f'Mean: {mean_path:.1f}')\n",
    "            ax3.legend()\n",
    "        else:\n",
    "            ax3.text(0.5, 0.5, 'No paths found\\nin sample', \n",
    "                    horizontalalignment='center', verticalalignment='center', \n",
    "                    transform=ax3.transAxes, fontsize=12)\n",
    "            ax3.set_title('Shortest Path Length Distribution')\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'Insufficient nodes\\nfor path analysis', \n",
    "                horizontalalignment='center', verticalalignment='center', \n",
    "                transform=ax3.transAxes, fontsize=12)\n",
    "        ax3.set_title('Shortest Path Length Distribution')\n",
    "        \n",
    "except Exception as e:\n",
    "    ax3.text(0.5, 0.5, f'Path analysis\\nnot available:\\n{str(e)[:30]}...', \n",
    "            horizontalalignment='center', verticalalignment='center', \n",
    "            transform=ax3.transAxes, fontsize=10)\n",
    "    ax3.set_title('Shortest Path Length Distribution')\n",
    "\n",
    "# 4. Network Summary Statistics\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')  # Turn off axis for text display\n",
    "\n",
    "# Prepare summary statistics\n",
    "stats_text = []\n",
    "stats_text.append(\"üìä NETWORK CONNECTIVITY SUMMARY\")\n",
    "stats_text.append(\"=\" * 40)\n",
    "stats_text.append(f\"Nodes: {G.number_of_nodes():,}\")\n",
    "stats_text.append(f\"Edges: {G.number_of_edges():,}\")\n",
    "stats_text.append(f\"Graph Type: {'Directed' if G.is_directed() else 'Undirected'}\")\n",
    "stats_text.append(f\"Density: {nx.density(G):.6f}\")\n",
    "\n",
    "# Connectivity status\n",
    "if G.is_directed():\n",
    "    stats_text.append(f\"Strongly Connected: {nx.is_strongly_connected(G)}\")\n",
    "    stats_text.append(f\"Weakly Connected: {nx.is_weakly_connected(G)}\")\n",
    "    if not nx.is_weakly_connected(G):\n",
    "        stats_text.append(f\"WCC Count: {nx.number_weakly_connected_components(G)}\")\n",
    "else:\n",
    "    stats_text.append(f\"Connected: {nx.is_connected(G)}\")\n",
    "    if not nx.is_connected(G):\n",
    "        stats_text.append(f\"CC Count: {nx.number_connected_components(G)}\")\n",
    "\n",
    "# Degree statistics\n",
    "degrees = [d for n, d in G.degree()]\n",
    "stats_text.append(\"\")\n",
    "stats_text.append(\"Degree Statistics:\")\n",
    "stats_text.append(f\"  Mean: {np.mean(degrees):.2f}\")\n",
    "stats_text.append(f\"  Median: {np.median(degrees):.2f}\")\n",
    "stats_text.append(f\"  Min: {min(degrees)}\")\n",
    "stats_text.append(f\"  Max: {max(degrees)}\")\n",
    "\n",
    "# Clustering (if available)\n",
    "try:\n",
    "    clustering = nx.average_clustering(G)\n",
    "    stats_text.append(f\"  Clustering: {clustering:.4f}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Display text\n",
    "ax4.text(0.05, 0.95, '\\n'.join(stats_text), \n",
    "         transform=ax4.transAxes, fontsize=11, \n",
    "         verticalalignment='top', horizontalalignment='left',\n",
    "         family='monospace',\n",
    "         bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Connectivity visualizations created!\")\n",
    "\n",
    "# Create a simple network layout visualization for smaller graphs\n",
    "if G.number_of_nodes() <= 100:\n",
    "    print(f\"\\nüï∏Ô∏è Creating network layout visualization...\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Choose layout based on graph size\n",
    "    if G.number_of_nodes() <= 20:\n",
    "        pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "    else:\n",
    "        pos = nx.spring_layout(G, k=1, iterations=30)\n",
    "    \n",
    "    # Color nodes by connected component\n",
    "    if G.is_directed():\n",
    "        components = list(nx.weakly_connected_components(G))\n",
    "    else:\n",
    "        components = list(nx.connected_components(G))\n",
    "    \n",
    "    # Create color map\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(components)))\n",
    "    node_colors = []\n",
    "    \n",
    "    for node in G.nodes():\n",
    "        for i, component in enumerate(components):\n",
    "            if node in component:\n",
    "                node_colors.append(colors[i])\n",
    "                break\n",
    "    \n",
    "    # Draw the graph\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=100, alpha=0.8)\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.5, width=0.5)\n",
    "    \n",
    "    if G.number_of_nodes() <= 30:\n",
    "        nx.draw_networkx_labels(G, pos, font_size=8, font_weight='bold')\n",
    "    \n",
    "    plt.title(f'Network Layout - {len(components)} Connected Component(s)', fontsize=14, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Network layout visualization created!\")\n",
    "    \n",
    "elif G.number_of_nodes() <= 500:\n",
    "    print(f\"\\nüï∏Ô∏è Creating simplified network visualization for {G.number_of_nodes()} nodes...\")\n",
    "    \n",
    "    # Sample nodes for visualization\n",
    "    sample_size = min(100, G.number_of_nodes())\n",
    "    sample_nodes = np.random.choice(list(G.nodes()), size=sample_size, replace=False)\n",
    "    subgraph = G.subgraph(sample_nodes)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    pos = nx.spring_layout(subgraph, k=1, iterations=30)\n",
    "    \n",
    "    nx.draw_networkx_nodes(subgraph, pos, node_color='lightblue', node_size=50, alpha=0.8)\n",
    "    nx.draw_networkx_edges(subgraph, pos, alpha=0.3, width=0.5)\n",
    "    \n",
    "    plt.title(f'Network Sample ({sample_size} nodes)', fontsize=14, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Sample network visualization created!\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Graph too large ({G.number_of_nodes()} nodes) for network layout visualization\")\n",
    "\n",
    "print(f\"\\nüéâ CONNECTIVITY ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a8f6c9",
   "metadata": {},
   "source": [
    "## 9. Layer 0 Connectivity Analysis\n",
    "\n",
    "This section analyzes the paths and connectivity between all nodes in Layer 0 (ground level). This is particularly important for understanding:\n",
    "- Horizontal connectivity at the lowest altitude\n",
    "- Path availability for low-altitude UAS operations\n",
    "- Network efficiency at ground level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive analysis of paths between all Layer 0 nodes\n",
    "print(\"üè¢ LAYER 0 CONNECTIVITY ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# First, identify Layer 0 nodes\n",
    "layer_0_nodes = []\n",
    "layer_attr = None\n",
    "\n",
    "# Try to find layer attribute\n",
    "if G.nodes():\n",
    "    sample_node = list(G.nodes())[0]\n",
    "    node_attrs = G.nodes[sample_node]\n",
    "    \n",
    "    # Check for common layer attribute names\n",
    "    for attr in ['layer', 'altitude', 'z', 'level', 'floor']:\n",
    "        if attr in node_attrs:\n",
    "            layer_attr = attr\n",
    "            break\n",
    "    \n",
    "    if layer_attr:\n",
    "        print(f\"‚úÖ Found layer attribute: '{layer_attr}'\")\n",
    "        \n",
    "        # Extract all Layer 0 nodes\n",
    "        for node in G.nodes():\n",
    "            layer = G.nodes[node].get(layer_attr)\n",
    "            if layer == 0:\n",
    "                layer_0_nodes.append(node)\n",
    "        \n",
    "        print(f\"Found {len(layer_0_nodes)} nodes in Layer 0\")\n",
    "    else:\n",
    "        print(\"‚ùå Could not identify layer attribute\")\n",
    "        print(\"Available node attributes:\", list(node_attrs.keys()))\n",
    "\n",
    "if len(layer_0_nodes) == 0:\n",
    "    print(\"\\n‚ö†Ô∏è No Layer 0 nodes found. Unable to perform analysis.\")\n",
    "else:\n",
    "    # Create subgraph of Layer 0 nodes\n",
    "    layer_0_subgraph = G.subgraph(layer_0_nodes)\n",
    "    \n",
    "    print(f\"\\nüìä LAYER 0 SUBGRAPH STATISTICS:\")\n",
    "    print(f\"Nodes in Layer 0: {layer_0_subgraph.number_of_nodes()}\")\n",
    "    print(f\"Edges in Layer 0: {layer_0_subgraph.number_of_edges()}\")\n",
    "    print(f\"Graph Type: {'Directed' if layer_0_subgraph.is_directed() else 'Undirected'}\")\n",
    "    \n",
    "    # Connectivity check\n",
    "    if layer_0_subgraph.is_directed():\n",
    "        is_strongly_connected = nx.is_strongly_connected(layer_0_subgraph)\n",
    "        is_weakly_connected = nx.is_weakly_connected(layer_0_subgraph)\n",
    "        print(f\"Strongly Connected: {is_strongly_connected}\")\n",
    "        print(f\"Weakly Connected: {is_weakly_connected}\")\n",
    "        \n",
    "        if not is_weakly_connected:\n",
    "            num_wcc = nx.number_weakly_connected_components(layer_0_subgraph)\n",
    "            print(f\"Number of Weakly Connected Components: {num_wcc}\")\n",
    "    else:\n",
    "        is_connected = nx.is_connected(layer_0_subgraph)\n",
    "        print(f\"Connected: {is_connected}\")\n",
    "        \n",
    "        if not is_connected:\n",
    "            num_cc = nx.number_connected_components(layer_0_subgraph)\n",
    "            print(f\"Number of Connected Components: {num_cc}\")\n",
    "    \n",
    "    # Degree distribution at Layer 0\n",
    "    layer_0_degrees = [d for n, d in layer_0_subgraph.degree()]\n",
    "    if layer_0_degrees:\n",
    "        print(f\"\\nüìà LAYER 0 DEGREE STATISTICS:\")\n",
    "        print(f\"Average Degree: {np.mean(layer_0_degrees):.2f}\")\n",
    "        print(f\"Median Degree: {np.median(layer_0_degrees):.2f}\")\n",
    "        print(f\"Min Degree: {min(layer_0_degrees)}\")\n",
    "        print(f\"Max Degree: {max(layer_0_degrees)}\")\n",
    "        \n",
    "        degree_counts = Counter(layer_0_degrees)\n",
    "        print(f\"\\nDegree Distribution:\")\n",
    "        for degree in sorted(degree_counts.keys()):\n",
    "            count = degree_counts[degree]\n",
    "            percentage = (count / len(layer_0_degrees)) * 100\n",
    "            print(f\"  Degree {degree}: {count} nodes ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Path analysis between all Layer 0 nodes\n",
    "    print(f\"\\nüõ§Ô∏è PATH ANALYSIS BETWEEN ALL LAYER 0 NODES:\")\n",
    "    \n",
    "    layer_0_node_list = list(layer_0_nodes)\n",
    "    total_pairs = len(layer_0_node_list) * (len(layer_0_node_list) - 1)\n",
    "    if not layer_0_subgraph.is_directed():\n",
    "        total_pairs = total_pairs // 2\n",
    "    \n",
    "    print(f\"Total node pairs to analyze: {total_pairs:,}\")\n",
    "    \n",
    "    # For very large Layer 0, we might need to sample\n",
    "    max_pairs_to_check = 10000\n",
    "    \n",
    "    if total_pairs <= max_pairs_to_check:\n",
    "        print(f\"Analyzing all {total_pairs:,} pairs...\")\n",
    "        analyze_all = True\n",
    "    else:\n",
    "        print(f\"Layer 0 is large - analyzing sample of {max_pairs_to_check:,} pairs...\")\n",
    "        analyze_all = False\n",
    "    \n",
    "    path_lengths = []\n",
    "    reachable_pairs = 0\n",
    "    unreachable_pairs = 0\n",
    "    pairs_checked = 0\n",
    "    \n",
    "    # Get the largest connected component for path analysis\n",
    "    if layer_0_subgraph.is_directed():\n",
    "        if nx.is_weakly_connected(layer_0_subgraph):\n",
    "            path_graph = layer_0_subgraph\n",
    "        else:\n",
    "            wcc = max(nx.weakly_connected_components(layer_0_subgraph), key=len)\n",
    "            path_graph = layer_0_subgraph.subgraph(wcc)\n",
    "            print(f\"Using largest weakly connected component: {len(wcc)} nodes\")\n",
    "    else:\n",
    "        if nx.is_connected(layer_0_subgraph):\n",
    "            path_graph = layer_0_subgraph\n",
    "        else:\n",
    "            cc = max(nx.connected_components(layer_0_subgraph), key=len)\n",
    "            path_graph = layer_0_subgraph.subgraph(cc)\n",
    "            print(f\"Using largest connected component: {len(cc)} nodes\")\n",
    "    \n",
    "    path_graph_nodes = list(path_graph.nodes())\n",
    "    \n",
    "    # Calculate paths\n",
    "    if analyze_all:\n",
    "        # Check all pairs\n",
    "        for i, source in enumerate(path_graph_nodes):\n",
    "            for j, target in enumerate(path_graph_nodes):\n",
    "                if source == target:\n",
    "                    continue\n",
    "                \n",
    "                if not layer_0_subgraph.is_directed() and j <= i:\n",
    "                    continue  # Skip duplicate pairs in undirected graph\n",
    "                \n",
    "                pairs_checked += 1\n",
    "                \n",
    "                try:\n",
    "                    length = nx.shortest_path_length(path_graph, source, target)\n",
    "                    path_lengths.append(length)\n",
    "                    reachable_pairs += 1\n",
    "                except nx.NetworkXNoPath:\n",
    "                    unreachable_pairs += 1\n",
    "                \n",
    "                # Progress indicator for large graphs\n",
    "                if pairs_checked % 1000 == 0:\n",
    "                    print(f\"  Processed {pairs_checked:,} / {total_pairs:,} pairs...\", end='\\r')\n",
    "    else:\n",
    "        # Sample pairs\n",
    "        np.random.seed(42)\n",
    "        sample_size = int(np.sqrt(max_pairs_to_check))\n",
    "        sample_nodes = np.random.choice(path_graph_nodes, size=min(sample_size, len(path_graph_nodes)), replace=False)\n",
    "        \n",
    "        for i, source in enumerate(sample_nodes):\n",
    "            for j, target in enumerate(sample_nodes):\n",
    "                if source == target:\n",
    "                    continue\n",
    "                \n",
    "                if not layer_0_subgraph.is_directed() and j <= i:\n",
    "                    continue\n",
    "                \n",
    "                pairs_checked += 1\n",
    "                \n",
    "                try:\n",
    "                    length = nx.shortest_path_length(path_graph, source, target)\n",
    "                    path_lengths.append(length)\n",
    "                    reachable_pairs += 1\n",
    "                except nx.NetworkXNoPath:\n",
    "                    unreachable_pairs += 1\n",
    "    \n",
    "    print(f\"\\n\")  # Clear progress line\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"üìä PATH ANALYSIS RESULTS:\")\n",
    "    print(f\"Pairs checked: {pairs_checked:,}\")\n",
    "    \n",
    "    if pairs_checked > 0:\n",
    "        print(f\"Reachable pairs: {reachable_pairs:,} ({reachable_pairs/pairs_checked*100:.1f}%)\")\n",
    "        print(f\"Unreachable pairs: {unreachable_pairs:,} ({unreachable_pairs/pairs_checked*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"Reachable pairs: {reachable_pairs:,} (No pairs to analyze)\")\n",
    "        print(f\"Unreachable pairs: {unreachable_pairs:,} (No pairs to analyze)\")\n",
    "    \n",
    "    if path_lengths:\n",
    "        print(f\"\\nüìè PATH LENGTH STATISTICS:\")\n",
    "        print(f\"Average shortest path: {np.mean(path_lengths):.2f}\")\n",
    "        print(f\"Median shortest path: {np.median(path_lengths):.2f}\")\n",
    "        print(f\"Min path length: {min(path_lengths)}\")\n",
    "        print(f\"Max path length: {max(path_lengths)}\")\n",
    "        print(f\"Standard deviation: {np.std(path_lengths):.2f}\")\n",
    "        \n",
    "        # Path length distribution\n",
    "        path_length_counts = Counter(path_lengths)\n",
    "        print(f\"\\nüìä PATH LENGTH DISTRIBUTION:\")\n",
    "        for length in sorted(path_length_counts.keys()):\n",
    "            count = path_length_counts[length]\n",
    "            percentage = (count / len(path_lengths)) * 100\n",
    "            print(f\"  Length {length}: {count} paths ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Calculate diameter and radius if possible\n",
    "        if len(path_graph_nodes) <= 500 and reachable_pairs > 0:\n",
    "            try:\n",
    "                if layer_0_subgraph.is_directed():\n",
    "                    if nx.is_strongly_connected(path_graph):\n",
    "                        diameter = nx.diameter(path_graph)\n",
    "                        radius = nx.radius(path_graph)\n",
    "                        print(f\"\\nüéØ LAYER 0 GRAPH METRICS:\")\n",
    "                        print(f\"Diameter (longest shortest path): {diameter}\")\n",
    "                        print(f\"Radius: {radius}\")\n",
    "                        \n",
    "                        # Find center and periphery nodes\n",
    "                        center = nx.center(path_graph)\n",
    "                        periphery = nx.periphery(path_graph)\n",
    "                        print(f\"Center nodes: {len(center)}\")\n",
    "                        print(f\"Periphery nodes: {len(periphery)}\")\n",
    "                else:\n",
    "                    if nx.is_connected(path_graph):\n",
    "                        diameter = nx.diameter(path_graph)\n",
    "                        radius = nx.radius(path_graph)\n",
    "                        print(f\"\\nüéØ LAYER 0 GRAPH METRICS:\")\n",
    "                        print(f\"Diameter (longest shortest path): {diameter}\")\n",
    "                        print(f\"Radius: {radius}\")\n",
    "                        \n",
    "                        # Find center and periphery nodes\n",
    "                        center = nx.center(path_graph)\n",
    "                        periphery = nx.periphery(path_graph)\n",
    "                        print(f\"Center nodes: {len(center)}\")\n",
    "                        print(f\"Periphery nodes: {len(periphery)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ö†Ô∏è Could not calculate diameter/radius: {e}\")\n",
    "        \n",
    "        # Visualize path length distribution\n",
    "        print(f\"\\nüìä Creating Layer 0 path length visualization...\")\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        fig.suptitle('Layer 0 Connectivity Analysis', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Path length histogram\n",
    "        ax1 = axes[0]\n",
    "        ax1.hist(path_lengths, bins=range(1, max(path_lengths)+2), alpha=0.7, \n",
    "                color='steelblue', edgecolor='navy')\n",
    "        ax1.set_xlabel('Path Length (hops)')\n",
    "        ax1.set_ylabel('Number of Paths')\n",
    "        ax1.set_title('Layer 0: Shortest Path Length Distribution')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        mean_path = np.mean(path_lengths)\n",
    "        ax1.axvline(mean_path, color='red', linestyle='--', alpha=0.7, \n",
    "                   label=f'Mean: {mean_path:.2f}')\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Summary statistics\n",
    "        ax2 = axes[1]\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        summary_text = []\n",
    "        summary_text.append(\"üìä LAYER 0 SUMMARY\")\n",
    "        summary_text.append(\"=\" * 35)\n",
    "        summary_text.append(f\"Total Nodes: {len(layer_0_nodes):,}\")\n",
    "        summary_text.append(f\"Total Edges: {layer_0_subgraph.number_of_edges():,}\")\n",
    "        summary_text.append(f\"Density: {nx.density(layer_0_subgraph):.6f}\")\n",
    "        summary_text.append(\"\")\n",
    "        summary_text.append(\"Connectivity:\")\n",
    "        if layer_0_subgraph.is_directed():\n",
    "            summary_text.append(f\"  Strongly: {nx.is_strongly_connected(layer_0_subgraph)}\")\n",
    "            summary_text.append(f\"  Weakly: {nx.is_weakly_connected(layer_0_subgraph)}\")\n",
    "        else:\n",
    "            summary_text.append(f\"  Connected: {nx.is_connected(layer_0_subgraph)}\")\n",
    "        summary_text.append(\"\")\n",
    "        summary_text.append(\"Path Statistics:\")\n",
    "        summary_text.append(f\"  Pairs checked: {pairs_checked:,}\")\n",
    "        summary_text.append(f\"  Reachable: {reachable_pairs:,}\")\n",
    "        summary_text.append(f\"  Unreachable: {unreachable_pairs:,}\")\n",
    "        if pairs_checked > 0:\n",
    "            summary_text.append(f\"  Reachability: {reachable_pairs/pairs_checked*100:.1f}%\")\n",
    "        else:\n",
    "            summary_text.append(f\"  Reachability: No pairs to analyze\")\n",
    "        summary_text.append(\"\")\n",
    "        summary_text.append(f\"  Avg path length: {np.mean(path_lengths):.2f}\")\n",
    "        summary_text.append(f\"  Max path length: {max(path_lengths)}\")\n",
    "        summary_text.append(f\"  Min path length: {min(path_lengths)}\")\n",
    "        \n",
    "        ax2.text(0.05, 0.95, '\\n'.join(summary_text), \n",
    "                transform=ax2.transAxes, fontsize=11,\n",
    "                verticalalignment='top', horizontalalignment='left',\n",
    "                family='monospace',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\", alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"‚úÖ Layer 0 visualization created!\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è No paths found between Layer 0 nodes\")\n",
    "    \n",
    "    # Network efficiency at Layer 0\n",
    "    if reachable_pairs > 0 and path_lengths:\n",
    "        avg_path_length = np.mean(path_lengths)\n",
    "        max_possible_efficiency = 1.0  # Direct connection\n",
    "        actual_efficiency = 1.0 / avg_path_length\n",
    "        \n",
    "        print(f\"\\n‚ö° LAYER 0 NETWORK EFFICIENCY:\")\n",
    "        print(f\"Average path efficiency: {actual_efficiency:.4f}\")\n",
    "        print(f\"Efficiency ratio: {actual_efficiency/max_possible_efficiency:.1%}\")\n",
    "        \n",
    "        # Calculate network robustness indicators\n",
    "        if len(layer_0_degrees) > 0:\n",
    "            degree_variance = np.var(layer_0_degrees)\n",
    "            degree_std = np.std(layer_0_degrees)\n",
    "            \n",
    "            print(f\"\\nüõ°Ô∏è LAYER 0 ROBUSTNESS INDICATORS:\")\n",
    "            print(f\"Degree variance: {degree_variance:.2f}\")\n",
    "            print(f\"Degree std dev: {degree_std:.2f}\")\n",
    "            \n",
    "            if degree_std < 1.0:\n",
    "                print(f\"  ‚Üí Highly regular structure (uniform connectivity)\")\n",
    "            elif degree_std < 2.0:\n",
    "                print(f\"  ‚Üí Moderately regular structure\")\n",
    "            else:\n",
    "                print(f\"  ‚Üí Irregular structure (varying connectivity)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Layer 0 connectivity analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fc0184",
   "metadata": {},
   "source": [
    "## 9.1 Layer 0 Multi-Layer Path Analysis\n",
    "\n",
    "This section analyzes whether Layer 0 nodes can reach other Layer 0 nodes by using paths that traverse through higher layers. This is crucial for understanding:\n",
    "- Multi-layer connectivity starting and ending at ground level\n",
    "- Whether UAS can reach any Layer 0 destination from any Layer 0 origin using vertical movement\n",
    "- Path diversity and redundancy through the 3D airspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825d878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of Layer 0 to Layer 0 paths using the full 3D graph (including vertical paths)\n",
    "print(\"üåê LAYER 0 MULTI-LAYER PATH ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Use the variables from the previous Layer 0 analysis\n",
    "if len(layer_0_nodes) == 0:\n",
    "    print(\"‚ö†Ô∏è No Layer 0 nodes found. Cannot perform multi-layer path analysis.\")\n",
    "else:\n",
    "    print(f\"Analyzing multi-layer paths between {len(layer_0_nodes)} Layer 0 nodes...\")\n",
    "    print(f\"Using full 3D graph with {G.number_of_nodes():,} total nodes and {G.number_of_edges():,} edges\")\n",
    "    \n",
    "    # Sample Layer 0 nodes if there are too many\n",
    "    max_layer_0_nodes = 100  # Limit for computational efficiency\n",
    "    \n",
    "    if len(layer_0_nodes) <= max_layer_0_nodes:\n",
    "        sample_layer_0_nodes = layer_0_nodes\n",
    "        print(f\"Analyzing all {len(sample_layer_0_nodes)} Layer 0 nodes\")\n",
    "    else:\n",
    "        np.random.seed(42)\n",
    "        sample_layer_0_nodes = np.random.choice(layer_0_nodes, size=max_layer_0_nodes, replace=False).tolist()\n",
    "        print(f\"Analyzing sample of {len(sample_layer_0_nodes)} Layer 0 nodes (out of {len(layer_0_nodes)} total)\")\n",
    "    \n",
    "    # Calculate paths between Layer 0 nodes using the full 3D graph\n",
    "    total_layer_0_pairs = len(sample_layer_0_nodes) * (len(sample_layer_0_nodes) - 1)\n",
    "    if not G.is_directed():\n",
    "        total_layer_0_pairs = total_layer_0_pairs // 2\n",
    "    \n",
    "    print(f\"Total Layer 0 to Layer 0 pairs to analyze: {total_layer_0_pairs:,}\")\n",
    "    \n",
    "    # Initialize counters\n",
    "    multilayer_path_lengths = []\n",
    "    multilayer_reachable_pairs = 0\n",
    "    multilayer_unreachable_pairs = 0\n",
    "    multilayer_pairs_checked = 0\n",
    "    paths_using_other_layers = 0\n",
    "    direct_layer_0_paths = 0\n",
    "    \n",
    "    # Track path details\n",
    "    path_layer_usage = {}  # layer -> count of paths using that layer\n",
    "    shortest_multilayer_path = None\n",
    "    longest_multilayer_path = None\n",
    "    \n",
    "    print(f\"\\nüîç ANALYZING MULTI-LAYER CONNECTIVITY:\")\n",
    "    print(f\"Checking paths from Layer 0 to Layer 0 through the entire 3D graph...\")\n",
    "    \n",
    "    # Calculate paths using the full graph\n",
    "    for i, source in enumerate(sample_layer_0_nodes):\n",
    "        for j, target in enumerate(sample_layer_0_nodes):\n",
    "            if source == target:\n",
    "                continue\n",
    "            \n",
    "            if not G.is_directed() and j <= i:\n",
    "                continue  # Skip duplicate pairs in undirected graph\n",
    "            \n",
    "            multilayer_pairs_checked += 1\n",
    "            \n",
    "            try:\n",
    "                # Find shortest path through the entire 3D graph\n",
    "                path = nx.shortest_path(G, source, target)\n",
    "                path_length = len(path) - 1  # Number of edges\n",
    "                multilayer_path_lengths.append(path_length)\n",
    "                multilayer_reachable_pairs += 1\n",
    "                \n",
    "                # Analyze which layers this path uses\n",
    "                path_layers = set()\n",
    "                layers_in_path = []\n",
    "                uses_non_layer_0 = False\n",
    "                \n",
    "                for node in path:\n",
    "                    node_layer = node_layers.get(node, 'unknown')\n",
    "                    if node_layer != 'unknown':\n",
    "                        path_layers.add(node_layer)\n",
    "                        layers_in_path.append(node_layer)\n",
    "                        if node_layer != 0:\n",
    "                            uses_non_layer_0 = True\n",
    "                \n",
    "                # Count layer usage\n",
    "                for layer in path_layers:\n",
    "                    if layer not in path_layer_usage:\n",
    "                        path_layer_usage[layer] = 0\n",
    "                    path_layer_usage[layer] += 1\n",
    "                \n",
    "                # Categorize path type\n",
    "                if uses_non_layer_0:\n",
    "                    paths_using_other_layers += 1\n",
    "                else:\n",
    "                    direct_layer_0_paths += 1\n",
    "                \n",
    "                # Track shortest and longest paths\n",
    "                if shortest_multilayer_path is None or path_length < len(shortest_multilayer_path) - 1:\n",
    "                    shortest_multilayer_path = path\n",
    "                if longest_multilayer_path is None or path_length > len(longest_multilayer_path) - 1:\n",
    "                    longest_multilayer_path = path\n",
    "                \n",
    "            except nx.NetworkXNoPath:\n",
    "                multilayer_unreachable_pairs += 1\n",
    "            \n",
    "            # Progress indicator\n",
    "            if multilayer_pairs_checked % 100 == 0:\n",
    "                print(f\"  Processed {multilayer_pairs_checked:,} / {total_layer_0_pairs:,} pairs...\", end='\\r')\n",
    "    \n",
    "    print(f\"\\n\")  # Clear progress line\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"üìä MULTI-LAYER PATH RESULTS:\")\n",
    "    print(f\"Layer 0 pairs checked: {multilayer_pairs_checked:,}\")\n",
    "    \n",
    "    if multilayer_pairs_checked > 0:\n",
    "        print(f\"Reachable via multi-layer paths: {multilayer_reachable_pairs:,} ({multilayer_reachable_pairs/multilayer_pairs_checked*100:.1f}%)\")\n",
    "        print(f\"Unreachable pairs: {multilayer_unreachable_pairs:,} ({multilayer_unreachable_pairs/multilayer_pairs_checked*100:.1f}%)\")\n",
    "        \n",
    "        if multilayer_reachable_pairs > 0:\n",
    "            print(f\"\\nüõ§Ô∏è PATH TYPE BREAKDOWN:\")\n",
    "            print(f\"Direct Layer 0 paths: {direct_layer_0_paths:,} ({direct_layer_0_paths/multilayer_reachable_pairs*100:.1f}%)\")\n",
    "            print(f\"Paths using other layers: {paths_using_other_layers:,} ({paths_using_other_layers/multilayer_reachable_pairs*100:.1f}%)\")\n",
    "            \n",
    "            print(f\"\\nüìè MULTI-LAYER PATH STATISTICS:\")\n",
    "            print(f\"Average path length: {np.mean(multilayer_path_lengths):.2f}\")\n",
    "            print(f\"Median path length: {np.median(multilayer_path_lengths):.2f}\")\n",
    "            print(f\"Min path length: {min(multilayer_path_lengths)}\")\n",
    "            print(f\"Max path length: {max(multilayer_path_lengths)}\")\n",
    "            print(f\"Standard deviation: {np.std(multilayer_path_lengths):.2f}\")\n",
    "            \n",
    "            # Path length distribution\n",
    "            multilayer_path_counts = Counter(multilayer_path_lengths)\n",
    "            print(f\"\\nüìä MULTI-LAYER PATH LENGTH DISTRIBUTION:\")\n",
    "            for length in sorted(multilayer_path_counts.keys())[:10]:  # Show first 10\n",
    "                count = multilayer_path_counts[length]\n",
    "                percentage = (count / len(multilayer_path_lengths)) * 100\n",
    "                print(f\"  Length {length}: {count} paths ({percentage:.1f}%)\")\n",
    "            \n",
    "            # Layer usage analysis\n",
    "            if path_layer_usage:\n",
    "                print(f\"\\nüèóÔ∏è LAYER USAGE IN PATHS:\")\n",
    "                print(f\"Layers used in Layer 0‚ÜíLayer 0 paths:\")\n",
    "                for layer in sorted(path_layer_usage.keys()):\n",
    "                    count = path_layer_usage[layer]\n",
    "                    percentage = (count / multilayer_reachable_pairs) * 100\n",
    "                    print(f\"  Layer {layer}: {count} paths ({percentage:.1f}%)\")\n",
    "            \n",
    "            # Example paths\n",
    "            if shortest_multilayer_path and longest_multilayer_path:\n",
    "                print(f\"\\nüéØ EXAMPLE PATHS:\")\n",
    "                \n",
    "                # Shortest path\n",
    "                shortest_layers = [node_layers.get(node, 'unknown') for node in shortest_multilayer_path]\n",
    "                print(f\"Shortest path ({len(shortest_multilayer_path)-1} hops):\")\n",
    "                print(f\"  Nodes: {' ‚Üí '.join(shortest_multilayer_path[:5])}{'...' if len(shortest_multilayer_path) > 5 else ''}\")\n",
    "                print(f\"  Layers: {' ‚Üí '.join(map(str, shortest_layers[:5]))}{'...' if len(shortest_layers) > 5 else ''}\")\n",
    "                \n",
    "                # Longest path (if different and not too long)\n",
    "                if len(longest_multilayer_path) != len(shortest_multilayer_path) and len(longest_multilayer_path) <= 20:\n",
    "                    longest_layers = [node_layers.get(node, 'unknown') for node in longest_multilayer_path]\n",
    "                    print(f\"\\nLongest path ({len(longest_multilayer_path)-1} hops):\")\n",
    "                    print(f\"  Nodes: {' ‚Üí '.join(longest_multilayer_path[:5])}{'...' if len(longest_multilayer_path) > 5 else ''}\")\n",
    "                    print(f\"  Layers: {' ‚Üí '.join(map(str, longest_layers[:5]))}{'...' if len(longest_layers) > 5 else ''}\")\n",
    "            \n",
    "            # Comparison with Layer 0 only paths\n",
    "            if 'path_lengths' in locals() and len(path_lengths) > 0:\n",
    "                layer_0_only_avg = np.mean(path_lengths)\n",
    "                multilayer_avg = np.mean(multilayer_path_lengths)\n",
    "                \n",
    "                print(f\"\\nüîÑ COMPARISON: Layer 0 Only vs Multi-Layer Paths:\")\n",
    "                print(f\"Layer 0 only average path length: {layer_0_only_avg:.2f}\")\n",
    "                print(f\"Multi-layer average path length: {multilayer_avg:.2f}\")\n",
    "                \n",
    "                if multilayer_avg < layer_0_only_avg:\n",
    "                    improvement = ((layer_0_only_avg - multilayer_avg) / layer_0_only_avg) * 100\n",
    "                    print(f\"‚úÖ Multi-layer paths are {improvement:.1f}% shorter on average\")\n",
    "                elif multilayer_avg > layer_0_only_avg:\n",
    "                    increase = ((multilayer_avg - layer_0_only_avg) / layer_0_only_avg) * 100\n",
    "                    print(f\"‚ö†Ô∏è Multi-layer paths are {increase:.1f}% longer on average\")\n",
    "                else:\n",
    "                    print(f\"‚û°Ô∏è Multi-layer and Layer 0 only paths have similar lengths\")\n",
    "                \n",
    "                # Reachability comparison\n",
    "                layer_0_reachability = reachable_pairs / pairs_checked * 100 if pairs_checked > 0 else 0\n",
    "                multilayer_reachability = multilayer_reachable_pairs / multilayer_pairs_checked * 100\n",
    "                \n",
    "                print(f\"\\nReachability comparison:\")\n",
    "                print(f\"Layer 0 only: {layer_0_reachability:.1f}% reachable\")\n",
    "                print(f\"Multi-layer: {multilayer_reachability:.1f}% reachable\")\n",
    "                \n",
    "                if multilayer_reachability > layer_0_reachability:\n",
    "                    improvement = multilayer_reachability - layer_0_reachability\n",
    "                    print(f\"‚úÖ Multi-layer connectivity improves reachability by {improvement:.1f} percentage points\")\n",
    "                else:\n",
    "                    print(f\"‚û°Ô∏è Similar reachability between approaches\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"No Layer 0 pairs to analyze\")\n",
    "    \n",
    "    # Create visualization\n",
    "    if multilayer_path_lengths:\n",
    "        print(f\"\\nüìä Creating multi-layer path visualization...\")\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        fig.suptitle('Layer 0 Multi-Layer Path Analysis', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Path length distribution\n",
    "        ax1 = axes[0]\n",
    "        ax1.hist(multilayer_path_lengths, bins=range(1, min(max(multilayer_path_lengths)+2, 21)), \n",
    "                alpha=0.7, color='green', edgecolor='darkgreen')\n",
    "        ax1.set_xlabel('Path Length (hops)')\n",
    "        ax1.set_ylabel('Number of Paths')\n",
    "        ax1.set_title('Multi-Layer Path Length Distribution')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        mean_multilayer = np.mean(multilayer_path_lengths)\n",
    "        ax1.axvline(mean_multilayer, color='red', linestyle='--', alpha=0.7, \n",
    "                   label=f'Mean: {mean_multilayer:.2f}')\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Path type comparison\n",
    "        ax2 = axes[1]\n",
    "        path_types = ['Direct\\nLayer 0', 'Using Other\\nLayers']\n",
    "        path_counts = [direct_layer_0_paths, paths_using_other_layers]\n",
    "        colors = ['lightblue', 'lightcoral']\n",
    "        \n",
    "        bars = ax2.bar(path_types, path_counts, color=colors, alpha=0.7, edgecolor='black')\n",
    "        ax2.set_ylabel('Number of Paths')\n",
    "        ax2.set_title('Path Type Distribution')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, count in zip(bars, path_counts):\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height + max(path_counts)*0.01,\n",
    "                    f'{count}', ha='center', va='bottom')\n",
    "        \n",
    "        # Layer usage\n",
    "        ax3 = axes[2]\n",
    "        if path_layer_usage:\n",
    "            layers = sorted(path_layer_usage.keys())\n",
    "            usage_counts = [path_layer_usage[layer] for layer in layers]\n",
    "            \n",
    "            ax3.bar([f'Layer {layer}' for layer in layers], usage_counts, \n",
    "                   alpha=0.7, color='orange', edgecolor='darkorange')\n",
    "            ax3.set_xlabel('Layer')\n",
    "            ax3.set_ylabel('Number of Paths Using Layer')\n",
    "            ax3.set_title('Layer Usage in Paths')\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "            plt.setp(ax3.get_xticklabels(), rotation=45)\n",
    "        else:\n",
    "            ax3.text(0.5, 0.5, 'No layer usage\\ndata available', \n",
    "                    horizontalalignment='center', verticalalignment='center',\n",
    "                    transform=ax3.transAxes, fontsize=12)\n",
    "            ax3.set_title('Layer Usage in Paths')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"‚úÖ Multi-layer path visualization created!\")\n",
    "\n",
    "print(f\"\\n‚úÖ Layer 0 multi-layer path analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37d55c5",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "This notebook provides a comprehensive analysis of the 3D lattice graph connectivity for UAS path planning. The analysis includes:\n",
    "\n",
    "### Key Insights:\n",
    "- **Graph Structure**: Detailed examination of the graph's basic properties including node/edge counts, degree distribution, and graph type\n",
    "- **Connectivity Status**: Assessment of whether the graph is connected (for undirected) or strongly/weakly connected (for directed)\n",
    "- **Component Analysis**: Identification and characterization of connected components and their sizes\n",
    "- **Path Efficiency**: Analysis of shortest paths, diameter, and average path lengths within the network\n",
    "- **Critical Nodes**: Identification of important nodes through various centrality measures\n",
    "- **Network Visualization**: Visual representations of connectivity patterns and graph structure\n",
    "\n",
    "### Applications for UAS Path Planning:\n",
    "- **Route Planning**: Connected components indicate which areas of the airspace are reachable from each other\n",
    "- **Network Resilience**: Centrality measures help identify critical nodes whose removal would most impact connectivity\n",
    "- **Path Optimization**: Shortest path analysis provides insights into the most efficient routes through the 3D airspace\n",
    "- **Airspace Utilization**: Density and clustering metrics show how well the lattice structure covers the available airspace\n",
    "\n",
    "### Next Steps:\n",
    "- Consider adding temporal or weather-based constraints to the connectivity analysis\n",
    "- Analyze connectivity at different altitude layers separately\n",
    "- Implement dynamic path planning algorithms using the connectivity insights\n",
    "- Evaluate the impact of obstacles or no-fly zones on network connectivity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
